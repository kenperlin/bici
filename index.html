<head>
  <meta charset="UTF-8" />
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"></script>
</head>

<body>
<script src=core/js/bici.js></script>
<script>loadProject('0924')</script>
<style>
  #overlayCanvas {
    position: fixed;
    top: 0;
    left: 0;
    z-index: 9999;
    pointer-events: none;
  }
</style>

<canvas id="overlayCanvas" width="640" height="480"></canvas>

<script>
function initMediapipe() {
  const canvas = document.getElementById("overlayCanvas");
  const ctx = canvas.getContext("2d");

  // ---------- Hands ----------
  const hands = new Hands({
    locateFile: (f) => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${f}`
  });
  hands.setOptions({
    maxNumHands: 2,
    modelComplexity: 1,
    minDetectionConfidence: 0.5,
    minTrackingConfidence: 0.5,
  });

  // ---------- FaceMesh ----------
  const faceMesh = new FaceMesh({
    locateFile: (f) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${f}`
  });
  faceMesh.setOptions({
    maxNumFaces: 1,
    refineLandmarks: true,   // includes eyes + lips details
    minDetectionConfidence: 0.5,
    minTrackingConfidence: 0.5,
  });

  // Store last detections to render together
  let lastHands = [];
  let lastFace = [];

  hands.onResults((results) => {
    lastHands = results.multiHandLandmarks || [];
  });
  faceMesh.onResults((results) => {
    lastFace = results.multiFaceLandmarks || [];
  });

  async function processFrame() {
    if (!window.webcam || window.webcam.videoWidth === 0) {
      requestAnimationFrame(processFrame);
      return;
    }
    canvas.width = window.webcam.videoWidth;
    canvas.height = window.webcam.videoHeight;

    // run both models
    await hands.send({ image: window.webcam });
    await faceMesh.send({ image: window.webcam });

    // now draw everything
    ctx.clearRect(0, 0, canvas.width, canvas.height);

    // hands
    lastHands.forEach((landmarks) => {
      landmarks.forEach((lm) => {
        const x = (1 - lm.x) * canvas.width; // mirrored
        const y = lm.y * canvas.height;
        ctx.beginPath();
        ctx.arc(x, y, 5, 0, 2 * Math.PI);
        ctx.fillStyle = "red";
        ctx.fill();
      });
    });

    // face
    lastFace.forEach((landmarks) => {
      landmarks.forEach((lm) => {
        const x = (1 - lm.x) * canvas.width; // mirrored
        const y = lm.y * canvas.height;
        ctx.beginPath();
        ctx.arc(x, y, 2, 0, 2 * Math.PI); // smaller dots for face
        ctx.fillStyle = "blue";
        ctx.fill();
      });
    });

    requestAnimationFrame(processFrame);
  }

  function startIfReady() {
    if (window.webcam && window.webcam.videoWidth > 0) {
      console.log("Webcam ready, starting frame loop");
      processFrame();
      return true;
    }
    return false;
  }

  window.webcam.addEventListener("canplay", () => {
    if (!startIfReady()) {
      const checkDims = setInterval(() => {
        if (startIfReady()) clearInterval(checkDims);
      }, 100);
    }
  });

  const watchdog = setInterval(() => {
    if (startIfReady()) clearInterval(watchdog);
  }, 500);
}

const waitForWebcam = setInterval(() => {
  if (window.webcam) {
    clearInterval(waitForWebcam);
    initMediapipe();
  }
}, 100);
</script>

</body>
